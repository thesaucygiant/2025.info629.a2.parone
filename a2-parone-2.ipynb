{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.10.19","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ed379349-653b-4d20-a2da-08b6787a338d","cell_type":"code","source":"#Course: INFO-629-686 - FA 25-26\n#Assignment 2: Demo of a recommender system application\n#Student: Anthony Parone\n#Date: October 2025\n#reference: https://machinelearningmastery.com/building-a-recommender-system-from-scratch-with-matrix-factorization-in-python/\n\n\n##libraries\nimport numpy as np #Installed Version numpy 1.26.4 - numpy needs to be < version 2\nimport pandas as pd #Installed Version pandas 2.3.3\nimport matplotlib.pyplot as plt #Installed Version matplotlib 1.5.0\nfrom surprise import Dataset, Reader, SVD #Installed Version surprise 0.1\nfrom surprise.model_selection import train_test_split, cross_validate\nfrom surprise import accuracy\nimport requests #Installed Version requests 2.32.5\nimport zipfile #Standard Python Library\nimport io #Standard Python Library\nimport os #Standard Python Library\nimport shutil\n\n\n##globals\n#set how many top N recommendations should be returned\nrecommend_count =10\n#set user\nuser_id = 10\n\n\n##functions##\n        \ndef get_movie_names():\n    movies_df = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1', header=None, usecols=[0, 1], names=['item_id', 'title'])\n    return movies_df\n\ndef get_ratings():\n    ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n    return ratings_df\n\ndef get_ratings_deleted_by_user():\n    shutil.copy('ml-100k/u.data', 'ml-100k/u_deleted.data')\n    ratings_deleted_by_user_df = pd.read_csv('ml-100k/u_deleted.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])\n    return ratings_deleted_by_user_df\n\ndef recommend_movies(user_id, n=10):\n    # List of all movies\n    all_movies = movies_df['item_id'].unique()\n    \n    # Movies already rated by the user\n    rated_movies = ratings_df[ratings_df['user_id'] == user_id]['item_id'].values\n    \n    # Movies not yet rated by the user\n    unrated_movies = np.setdiff1d(all_movies, rated_movies)\n    \n    # Predicting ratings on unseen movies, by using the trained SVD model\n    predictions = []\n    for item_id in unrated_movies:\n        predicted_rating = model.predict(user_id, item_id).est\n        predictions.append((item_id, predicted_rating))\n    \n    # Rank predictions by estimated rating\n    predictions.sort(key=lambda x: x[1], reverse=True)\n    \n    # Get top N recommendations\n    top_recommendations = predictions[:n]\n    \n    # Fetch movie titles associated with top N recommendations\n    recommendations = pd.DataFrame(top_recommendations, columns=['item_id', 'predicted_rating'])\n    recommendations = recommendations.merge(movies_df, on='item_id')\n    \n    return recommendations\n\ndef display_data_summary(ratings_df):\n    print(f\"Data Set Description:\")\n    #print(f\"Dataset shape: {ratings_df.shape}\")\n    #print(f\"Dataset columns: {ratings_df.head(1)}\")\n    print(f\"Number of unique users: {ratings_df['user_id'].nunique()}\")\n    print(f\"Number of unique movies: {ratings_df['item_id'].nunique()}\")\n    print(f\"Number of ratings: {len(ratings_df)}\")\n    print(f\"Range of ratings: {ratings_df['rating'].min()} to {ratings_df['rating'].max()}\")\n\n\n\n##Application Start\n\n#begin data load\n#load movie names\nmovies_df = get_movie_names()\n#movielens:user data\nratings_df = get_ratings()\n\n\n\n#------------------------------------------------------------------------------------------\n#recomendations by user_id - no changes to data set\n##train the model and retrieve recommendations\nreader = Reader(rating_scale=(1, 5))\ndata = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], reader)\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\nmodel = SVD(n_factors=20, lr_all=0.01, reg_all=0.01, n_epochs=20, random_state=42)\nmodel.fit(trainset)\npredictions = model.test(testset)\nrmse = accuracy.rmse(predictions)\nmae = accuracy.mae(predictions)\ncv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\nrecommendations = recommend_movies(user_id, n=recommend_count)\n\n#output\nprint(f\"---------------------------------------------------------------------------\")\n#display dataset summary\ndisplay_data_summary(ratings_df)\nprint(f\"Recomendations and Ratings\")\nprint(f\"\\nTop 10 MovieLens Ratings for {user_id}:\")\nprint(ratings_df.loc[ratings_df['user_id'] == user_id].nlargest(10, 'rating'))\nprint(f\"\\nTop {recommend_count} recommended movies for user {user_id}:\")\nprint(recommendations[['title', 'predicted_rating']])\n\n\n#------------------------------------------------------------------------------------------\n#recomendations by user_id - all ratings for this user_id are set to the same value\nnew_rating = 2\n#assign new ratings by user_id\nratings_df.loc[ratings_df['user_id'] == user_id, 'rating'] = new_rating\n\n##train the model and retrieve recommendations\nreader = Reader(rating_scale=(1, 5))\ndata = Dataset.load_from_df(ratings_df[['user_id', 'item_id', 'rating']], reader)\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\nmodel = SVD(n_factors=20, lr_all=0.01, reg_all=0.01, n_epochs=20, random_state=42)\nmodel.fit(trainset)\npredictions = model.test(testset)\nrmse = accuracy.rmse(predictions)\nmae = accuracy.mae(predictions)\ncv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\nupdated_recommendations = recommend_movies(user_id, n=recommend_count)\n\n#output\nprint(f\"------------------------------------------------------------------------------------------\")\n#display dataset summary\ndisplay_data_summary(ratings_df)\nprint(f\"\\nTop 10 Ratings for user {user_id} after updating ratings to the value of {new_rating}:\")\nprint(ratings_df.loc[ratings_df['user_id'] == user_id].nlargest(10, 'item_id'))\nprint(f\"\\nTop {recommend_count} recommended movies for user {user_id} after updating ratings to the value of {new_rating}:\")\nprint(updated_recommendations[['title', 'predicted_rating']])\n\n\n#------------------------------------------------------------------------------------------\n#recomendations by user_id - all ratings for this user_id are deleted\n#copy u.data -->u-deleted.data and reload\nratings_deleted_by_user_df = get_ratings_deleted_by_user()\nindices_to_drop = ratings_deleted_by_user_df[ratings_deleted_by_user_df['user_id'] == user_id].index\nratings_deleted_by_user_df.drop(indices_to_drop, inplace=True)\n\n##train the model and retrieve recommendations\nreader = Reader(rating_scale=(1, 5))\ndata = Dataset.load_from_df(ratings_deleted_by_user_df[['user_id', 'item_id', 'rating']], reader)\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\nmodel = SVD(n_factors=20, lr_all=0.01, reg_all=0.01, n_epochs=20, random_state=42)\nmodel.fit(trainset)\npredictions = model.test(testset)\nrmse = accuracy.rmse(predictions)\nmae = accuracy.mae(predictions)\ncv_results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\ndeleted_recommendations = recommend_movies(user_id, n=recommend_count)\n\n#output\nprint(f\"------------------------------------------------------------------------------------------\")\n#display dataset summary\ndisplay_data_summary(ratings_deleted_by_user_df)\nprint(f\"\\nTop 10 Ratings for user {user_id} after deleting their ratings:\")\nprint(ratings_df.loc[ratings_df['user_id'] == user_id].nlargest(10, 'item_id'))\nprint(f\"\\nTop {recommend_count} recommended movies for user {user_id} after deleting ratings:\")\nprint(deleted_recommendations[['title', 'predicted_rating']])\n\n\n\n\n\n","metadata":{"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m#Installed Version pandas 2.3.3\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m#Installed Version matplotlib 1.5.0\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, Reader, SVD \u001b[38;5;66;03m#Installed Version surprise 0.1\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, cross_validate\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msurprise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"],"ename":"ModuleNotFoundError","evalue":"No module named 'surprise'","output_type":"error"}],"execution_count":1},{"id":"1819c5e6-6a9c-49c8-98fc-c49fc30f6c39","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}